{
    "cells": [
     {
      "cell_type": "markdown",
      "id": "66e8d14b",
      "metadata": {},
      "source": [
       "# Tutorial: Machine Learning with QIIME 2\n",
       "\n",
       "This notebook contains materials accompanying the Functional Genomics Center ZÃ¼rich course **Next-Generation Sequencing Applied to Metagenomics (BIO638)**. The notebook and corresponding setup script were adapted from the [**Advanced Block Course: Computational Biology**](https://github.com/bokulich-lab/advanced-comp-bio-tutorial.git); all source code is licensed under the Apache License 2.0.\n",
       "\n",
       "Save your own local copy of this notebook by using `File > Save a copy in Drive`. At some point you may be prompted to trust the notebook. We promise that it is safe ðŸ¤ž\n",
       "\n",
       "**Notes (optional):**\n",
       "\n",
       "The Google Colab notebook environment will interpret any command as Python code by default. If we want to run bash commands we will have to prefix them by `!`. So any command you see with a leading `!` is a bash command and if you wanted to run it in your terminal you would omit the leading `!`. For example, if in the Colab notebook you ran `!wget` you would just run `wget` in your terminal. \n",
       "\n",
       "In this notebook we use the `!` prefix because we run all QIIME 2 commands using the [`q2cli`](https://github.com/qiime2/q2cli/) (QIIME 2 command-line interface). However, QIIME 2 also has a python API and a Galaxy interface. You can learn more about these and other QIIME 2 interfaces at https://qiime2.org/."
      ]
     },
     {
      "cell_type": "markdown",
      "id": "d8336c0f",
      "metadata": {},
      "source": [
       "## Setup\n",
       "\n",
       "### File setup\n",
       "\n",
       "The dataset used for this tutorial is confidential and not yet publicly released; please do not share outside this group. We include a series of manual download and upload steps to allow the data to be used for this course.\n",
       "\n",
       "ðŸ›‘ **ACTION** ðŸ›‘\n",
       "<br>\n",
       "*FGCZ course attendees: Please follow the download/upload steps on the course PowerPoint slide. Other participants may otherwise add your own datasets in the form of QIIME 2 artifacts.*\n",
       "\n",
       "<img src=\"assets/upload_guide.png\" width=800>"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "b27a7190-c53a-452b-bb6c-fff84ec1d184",
      "metadata": {},
      "source": [
       "After the manual downloads and uploads, we need to set some variables to run the notebook effectively. The code block below set variables according to the FGCZ course dataset; please feel free to modify this as necessary.\n",
       "\n",
       "ðŸŸ¡ **ACTION** ðŸŸ¡\n",
       "<br>\n",
       "*Non-FGCZ course attendees: Double-check the following code block. You may modify this block for other datasets of interest in the future.*"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "849321b3-d623-4786-a6b1-13d68bdc12e7",
      "metadata": {},
      "outputs": [],
      "source": [
       "feature_table_file = \"/content/feature_table.qza\"\n",
       "feature_table_tss_file = \"/content/feature_table_tss.qza\"\n",
       "metadata_file = \"/content/metadata.tsv\""
      ]
     },
     {
      "cell_type": "markdown",
      "id": "72f112dd-6c92-4bc8-9903-b66810eba77d",
      "metadata": {},
      "source": [
       "### Environment setup\n",
       "\n",
       "QIIME 2 is usually installed by following the [official installation instructions](https://docs.qiime2.org/2024.5/install/). However, because we are using Google Colab and there are some caveats to using conda here, we will have to hack around the installation a little. But no worries, we provide a setup script below which does all this work for us. ðŸ˜Œ Let's start by pulling a local copy of the project repository down from GitHub.\n",
       "\n",
       "From here, you run the entire notebook by selecting `Runtime > Run all` from the menu in Google Colab. Some steps are time-comsuming and the entire notebook may take up to 30-60 minutes, so run the entire notebook now and we will inspect the commands and results as we work through as a class.\n",
       "\n",
       "ðŸ›‘ **ACTION** ðŸ›‘\n",
       "<br>\n",
       "*Run every cell in the notebook using the instructions above.*"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb370f02",
      "metadata": {},
      "outputs": [],
      "source": [
       "! git clone https://github.com/bokulich-lab/fgcz-metagenomics-workshop.git materials\n",
       "! mkdir /content/prefetch_cache"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "ca93f535-e068-46c4-a7cc-2cb003a125ed",
      "metadata": {},
      "source": [
       "We will move into the `materials/` directory."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c307202-63c5-4a14-aa2c-8cf62798c147",
      "metadata": {},
      "outputs": [],
      "source": [
       "%cd materials"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "c489ed10",
      "metadata": {},
      "source": [
       "Now we are ready to set up our environment. This will take about 10 minutes.\n",
       "<br>\n",
       "**Note:** This setup is only relevant for Google Colaboratory and will not work on your local machine. Please follow the [official installation instructions](https://docs.qiime2.org/2024.5/install/) for that."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b891377",
      "metadata": {},
      "outputs": [],
      "source": [
       "%run setup_qiime2"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "40379ada",
      "metadata": {},
      "source": [
       "And we will use some Python packages below, so let's load these here:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "396ca0ba",
      "metadata": {},
      "outputs": [],
      "source": [
       "import numpy as np\n",
       "import pandas as pd\n",
       "import seaborn as sns"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "fa2d312e",
      "metadata": {},
      "source": [
       "## Predicting categorical data\n",
       "\n",
       "*Supervised learning classifiers* predict the categorical metadata classes of unlabeled samples by learning the composition of labeled training samples. For example, we may use a classifier to diagnose or predict disease susceptibility based on stool microbiome composition, or predict sample type as a function of the sequence variants, microbial taxa, or metabolites detected in a sample. In this tutorial, we will use the read processing tutorial data to train a classifier that predicts body site from which a sample was collected.\n",
       "\n",
       "Sections:\n",
       "1. Train and test a categorical classifier\n",
       "2. Optimize feature selection\n",
       "3. Perform nested cross-validation\n",
       "\n",
       "### Training/testing classifier\n",
       "\n",
       "We will train and test a classifier that predicts which body site a sample originated from, based on its microbial composition. We will do so using the `classify-samples` pipeline, which performs a series of steps:\n",
       "\n",
       "1. The input samples are randomly split into a `training` set and a `test` set. The test set is held out until the end of the pipeline, allowing us to test accuracy on a set of samples that was not used for model training. The fraction of input samples to include in the test set is adjusted with the `--p-test-size` parameter.\n",
       "\n",
       "2. We train the learning model using the training set samples. The model is trained to predict a specific `target` value for each sample (contained in a metadata column) based on the feature data associated with that sample. A range of different estimators can be selected using the `estimator` parameter; more details on individual estimators can be found in the [scikit-learn documentation](http://scikit-learn.org/stable/supervised_learning.html) (not sure which to choose? See the [estimator selection flowchart](http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)).\n",
       "\n",
       "3. The trained model is used to predict the target values for each test sample, based on the feature data associated with that sample, and predict class probabilities for each sample. Class probabilities are the likelihood that a sample belongs to each class (i.e., group of samples with the same `target` value).\n",
       "\n",
       "4. Model accuracy is calculated by comparing each test sampleâ€™s predicted value to the true value for that sample."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca325e95",
      "metadata": {
       "scrolled": true
      },
      "outputs": [],
      "source": [
       "pd.read_csv(metadata_file,\n",
       "            sep=\"\\t\",\n",
       "            index_col=0)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bb8d296",
      "metadata": {},
      "outputs": [],
      "source": [
       "! qiime sample-classifier classify-samples \\\n",
       "    --i-table {feature_table_file} \\\n",
       "    --m-metadata-file {metadata_file} \\\n",
       "    --m-metadata-column body_site \\\n",
       "    --p-estimator RandomForestClassifier \\\n",
       "    --p-random-state 123 \\\n",
       "    --output-dir rf_classifier"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "454b44f5",
      "metadata": {},
      "source": [
       "Use [QIIME 2 View](https://view.qiime2.org) to check out `accuracy_results.qzv`, which presents classification accuracy results in the form of a confusion matrix, as well as [Receiver Operating Characteristic (ROC) curves](https://en.wikipedia.org/wiki/Receiver_operating_characteristic).\n",
       "\n",
       "ðŸ›‘ **ACTION** ðŸ›‘\n",
       "<br>\n",
       "*Question: What other metadata can we predict with `classify-samples`?* Take a look at the metadata columns in the metadata TSV and try some other categorical columns. Not all metadata can be easily learned by the classifier!"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8649956-c30c-4c78-b7a6-11c9bc2db07d",
      "metadata": {},
      "outputs": [],
      "source": [
       "# Your code here! Run q2-sample-classifier with a different metadata category."
      ]
     },
     {
      "cell_type": "markdown",
      "id": "be8eda28-24a2-4563-8fe3-b18d43a27122",
      "metadata": {},
      "source": [
       "Now we will look at some of the details of our model predictions."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "d763bdf5",
      "metadata": {},
      "outputs": [],
      "source": [
       "! qiime metadata tabulate \\\n",
       "    --m-input-file rf_classifier/predictions.qza \\\n",
       "    --o-visualization rf_classifier/predictions.qzv"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc45c135",
      "metadata": {},
      "outputs": [],
      "source": [
       "! qiime metadata tabulate \\\n",
       "    --m-input-file rf_classifier/probabilities.qza \\\n",
       "    --o-visualization rf_classifier/probabilities.qzv"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "93d9e305",
      "metadata": {},
      "outputs": [],
      "source": [
       "! qiime metadata tabulate \\\n",
       "    --m-input-file rf_classifier/test_targets.qza \\\n",
       "    --m-input-file rf_classifier/predictions.qza \\\n",
       "    --o-visualization rf_classifier/test_targets_predictions.qzv"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "b14091e5",
      "metadata": {},
      "source": [
       "A list of all features, and their relative importances (or feature weights or model coefficients, depending on the learning model used), will be reported in `feature_importance.qza`. Features with higher importance scores were more useful for distinguishing classes.\n",
       "\n",
       "ðŸ›‘ **ACTION** ðŸ›‘\n",
       "<br>\n",
       "*Question: What are the 5 most important features in the model?*"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "eca71664",
      "metadata": {},
      "outputs": [],
      "source": [
       "! qiime metadata tabulate \\\n",
       "    --m-input-file rf_classifier/feature_importance.qza \\\n",
       "    --o-visualization rf_classifier/feature_importance.qzv"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "e299f416",
      "metadata": {},
      "source": [
       "### Feature selection\n",
       "\n",
       "If `--p-optimize-feature-selection` is enabled, only the selected features (i.e., the most important features, which maximize model accuracy, as determined using [recursive feature elimination](http://scikit-learn.org/stable/modules/feature_selection.html#recursive-feature-elimination)) will be reported in this artifact, and all other results (e.g., model accuracy and predictions) that are output use the final, optimized model that utilizes this reduced feature set. This allows us to not only see which features are most important (and hence used by the model). "
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ff7ab87",
      "metadata": {},
      "outputs": [],
      "source": [
       "! qiime sample-classifier classify-samples \\\n",
       "    --i-table {feature_table_file} \\\n",
       "    --m-metadata-file {metadata_file} \\\n",
       "    --m-metadata-column body_site \\\n",
       "    --p-optimize-feature-selection \\\n",
       "    --p-estimator RandomForestClassifier \\\n",
       "    --p-n-estimators 20 \\\n",
       "    --p-random-state 123 \\\n",
       "    --output-dir rf_opt_classifier"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "90311f34",
      "metadata": {},
      "outputs": [],
      "source": [
       "! qiime metadata tabulate \\\n",
       "    --m-input-file rf_opt_classifier/feature_importance.qza \\\n",
       "    --o-visualization rf_opt_classifier/feature_importance.qzv"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "90d6b9cb",
      "metadata": {},
      "source": [
       "ðŸ›‘ **ACTION** ðŸ›‘\n",
       "<br>\n",
       "*Question: What are the 5 most important taxa in this model?* How do they differ from the five most important taxa in the previous model?"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "a86385f4",
      "metadata": {},
      "source": [
       "We can use that information to filter out uninformative features from our feature table for other downstream analyses outside of `q2-sample-classifier`."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c5a6311",
      "metadata": {},
      "outputs": [],
      "source": [
       "! qiime feature-table filter-features \\\n",
       "    --i-table {feature_table_file} \\\n",
       "    --m-metadata-file rf_opt_classifier/feature_importance.qza \\\n",
       "    --o-filtered-table rf_opt_classifier/important_feature_table.qza"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "c19bd83f",
      "metadata": {},
      "source": [
       "We can also use the `heatmap` pipeline to generate an abundance heatmap of the most important features in each sample or group. Letâ€™s make a heatmap of the top 30 most abundant features in each of our sample types."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b493f6d",
      "metadata": {},
      "outputs": [],
      "source": [
       "! qiime sample-classifier heatmap \\\n",
       "    --i-table {feature_table_file} \\\n",
       "    --i-importance rf_opt_classifier/feature_importance.qza \\\n",
       "    --m-sample-metadata-file {metadata_file} \\\n",
       "    --m-sample-metadata-column body_site \\\n",
       "    --p-group-samples \\\n",
       "    --p-feature-count 30 \\\n",
       "    --o-filtered-table rf_opt_classifier/important_feature_table_top_30.qza \\\n",
       "    --o-heatmap rf_opt_classifier/important_feature_heatmap.qzv"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "70d3a438",
      "metadata": {},
      "source": [
       "### Nested cross-validation\n",
       "\n",
       "In the examples above, we split the data sets into training and test sets for model training and testing. It is essential that we keep a test set that the model has never seen before for validating model performance. But what if we want to predict target values for each sample in a data set? For that, we use nested cross validation (NCV). This can be valuable in a number of different cases, e.g. predicting mislabeled samples (those that are classified incorrectly during NCV) or for assessing estimator variance (since multiple models are trained during NCV, we can look at the variance in their accuracy)."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "060c2c02",
      "metadata": {},
      "outputs": [],
      "source": [
       "! qiime sample-classifier classify-samples-ncv \\\n",
       "    --i-table {feature_table_file} \\\n",
       "    --m-metadata-file {metadata_file} \\\n",
       "    --m-metadata-column body_site \\\n",
       "    --p-estimator RandomForestClassifier \\\n",
       "    --p-random-state 123 \\\n",
       "    --output-dir rf_classifier_ncv"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "235729ab",
      "metadata": {},
      "outputs": [],
      "source": [
       "! qiime sample-classifier confusion-matrix \\\n",
       "    --i-predictions rf_classifier_ncv/predictions.qza \\\n",
       "    --i-probabilities rf_classifier_ncv/probabilities.qza \\\n",
       "    --m-truth-file {metadata_file} \\\n",
       "    --m-truth-column body_site \\\n",
       "    --o-visualization rf_classifier_ncv/ncv_confusion_matrix.qzv"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "b7bdb9f1-709f-4fb2-917c-5c26e53fdcc5",
      "metadata": {},
      "source": [
       "ðŸ›‘ **ACTION** ðŸ›‘\n",
       "<br>\n",
       "*Question: Did your nested cross-validation perform similarly to your previous train/test split? Is this what you expected?*"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "7dc24a5c",
      "metadata": {},
      "source": [
       "## Notes\n",
       "\n",
       "### Warning\n",
       "\n",
       "Just as with any statistical method, the actions described in this plugin require adequate sample sizes to achieve meaningful results. As a rule of thumb, a minimum of [approximately 50 samples](http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) should be provided. Categorical metadata columns that are used as classifier targets should have a minimum of 10 samples per unique value, and continuous metadata columns that are used as regressor targets should not contain many outliers or grossly uneven distributions. Smaller counts will result in inaccurate models, and may result in errors.\n",
       "\n",
       "\n",
       "### Best practices for `q2-sample-classifier`\n",
       "As this tutorial has demonstrated, q2-sample-classifier can be extremely powerful for feature selection and metadata prediction. However, with power comes responsibility. Unsuspecting users are at risk of committing grave errors, particularly from overfitting and data leakage. Here follows a list (though inevitably incomplete) of ways that users can abuse this plugin, yielding misleading results. Do not do these things. More extensive guides exist for avoiding data leakage and overfitting in general, so this list focuses on bad practices that are particular to this plugin and to biological data analysis.\n",
       "\n",
       "1. Data leakage occurs whenever a learning model learns (often inadvertently) about test sample data, leading to unduly high performance estimates.\n",
       "\n",
       "    - Model accuracy should always be assessed on test data that has never been seen by the learning model. The pipelines and nested cross-validation methods in q2-sample-classifier (including those described in this tutorial) do this by default. However, care must be taken when using the fit-* and predict-* methods independently.\n",
       "\n",
       "    - In some situations, technical replicates could be problematic and lead to pseudo-data leakage, depending on experimental design and technical precision. If in doubt, group your feature table to average technical replicates, or filter technical replicates from your data prior to supervised learning analysis.\n",
       "\n",
       "2. Overfitting occurs whenever a learning model is trained to overperform on the training data but, in doing so, cannot generalize well to other data sets. This can be problematic, particularly on small data sets and whenever input data have been contorted in inappropriate ways.\n",
       "\n",
       "    - If the learning model is intended to predict values from data that is produced in batches (e.g., to make a diagnosis on microbiome sequence data that will be produced in a future analysis), consider incorporating multiple batches in your training data to reduce the likelihood that learning models will overfit on batch effects and similar noise.\n",
       "\n",
       "    - Similarly, be aware that batch effects can strongly impact performance, particularly if these are covariates with the target values that you are attempting to predict. For example, if you wish to classify whether samples belong to one of two different groups and those groups were analyzed on separate sequencing runs (for microbiome amplicon sequence data), training a classifier on these data will likely lead to inaccurate results that will not generalize to other data sets."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbfd9cbe-c256-4bfc-a7e9-f92e24ae9d8a",
      "metadata": {},
      "outputs": [],
      "source": []
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "qiime2-2023.2",
      "language": "python",
      "name": "qiime2-2023.2"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
     },
     "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
     },
     "varInspector": {
      "cols": {
       "lenName": 16,
       "lenType": 16,
       "lenVar": 40
      },
      "kernels_config": {
       "python": {
        "delete_cmd_postfix": "",
        "delete_cmd_prefix": "del ",
        "library": "var_list.py",
        "varRefreshCmd": "print(var_dic_list())"
       },
       "r": {
        "delete_cmd_postfix": ") ",
        "delete_cmd_prefix": "rm(",
        "library": "var_list.r",
        "varRefreshCmd": "cat(var_dic_list()) "
       }
      },
      "types_to_exclude": [
       "module",
       "function",
       "builtin_function_or_method",
       "instance",
       "_Feature"
      ],
      "window_display": false
     }
    },
    "nbformat": 4,
    "nbformat_minor": 5
   }
   